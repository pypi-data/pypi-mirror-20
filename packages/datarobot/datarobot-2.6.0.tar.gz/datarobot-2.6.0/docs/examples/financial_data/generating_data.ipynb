{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Dataset\n",
    "This notebook shows some of the steps required in creating a dataset from a third party's\n",
    "data. It has very little to do with DataRobot, and if you're mostly interested in learning\n",
    "about how to use the DataRobot Python Client, then you could skip reading this section and miss\n",
    "out on very little. In order to have the data necessary for the other notebook, you will\n",
    "need to make sure that this notebook runs.\n",
    "\n",
    "## What do I need to do?\n",
    "### Get an API Key\n",
    "The data we will be using is owned by the Federal Reserve Bank of St. Louis. They have an\n",
    "API for which you will need a key. The key is free, don't worry. Grab one at\n",
    "https://research.stlouisfed.org/docs/api/fred/\n",
    "\n",
    "To run this notebook without any changes, you will need to save your API key in a file\n",
    "in the same directory from which you run this notebook, and call the name of the file\n",
    "`api_key`.\n",
    "\n",
    "### Install the fredapi package\n",
    "You will also need this python client package, which makes accessing the data incredibly\n",
    "easy.\n",
    "\n",
    "`pip install fredapi`\n",
    "\n",
    "## What will we do with this data?\n",
    "We're going to predict the future and get rich. \n",
    "\n",
    "More concretely, we're going to use historical economic data to build a forecasting\n",
    "model for whether or not the US Economy will be in recession in 13 weeks from now.\n",
    "\n",
    "## The FRED Economic Data\n",
    "The Federal Reserve Bank of St. Louis provides a rich set of historical financial \n",
    "data, plus a REST API to access this data.\n",
    "\n",
    "We have also written some utilities in order to make it easy to combine data \n",
    "series with different date frequencies in a technique known as Last Observation Carried Forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import datetime\n",
    "import fredapi\n",
    "import pandas as pd\n",
    "import timetools\n",
    "fred = fredapi.Fred(api_key_file='api_key')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the data\n",
    "There is a lot of data accessible through the FRED API. More than a quarter million\n",
    "data series, actually. That's probably too much to all be useful. \n",
    "\n",
    "We selected this set of series by starting with a subset of data specifically\n",
    "related to the US Economy, and started filtering out forecast data, data that\n",
    "was a pseudo-indicator date (which is a big data leak for this problem),\n",
    "eventually ending up with the collection of series you see in the cell below.\n",
    "It wasn't really a scientific process, there are certainly more robust ways\n",
    "to go about it.\n",
    "\n",
    "You can go learn about any of these on the FRED website, like this:\n",
    "https://research.stlouisfed.org/fred2/series/A007RO1Q156NBEA\n",
    "That is the webpage for the first data series in the cell below. You can\n",
    "also get much of that data through the API, using the `get_series_info`\n",
    "method like we do in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "good_columns = [\n",
    "    u'A007RO1Q156NBEA', u'A011RE1Q156NBEA', u'A011RJ2Q224SBEA',\n",
    "    u'A021RO1Q156NBEA', u'A021RY2Q224SBEA', u'A191RV1Q225SBEA',\n",
    "    u'A765RL1Q225SBEA', u'A798RS2Q224SBEA', u'B808RA3Q086SBEA',\n",
    "    u'CLSACBQ158SBOG', u'CORESTICKM158SFRBATL', u'DLTRUCKSSAAR',\n",
    "    u'DNDGRY2Q224SBEA', u'DONGRS2Q224SBEA', u'DPCERV1Q225SBEA',\n",
    "    u'DTRSRZ2Q224SBEA', u'LNS14024886', u'LNU02300000', u'LNU04000003',\n",
    "    u'M1V', u'M2MOWN', u'M2V', u'MVAAUTOASS', u'NAPMNOI',\n",
    "    u'NECDFNA066MNFRBPHI', u'NOCDSA156MSFRBPHI', u'PERMIT',\n",
    "    u'PERMITMWNSA', u'PRS84006173', u'RCPHBS',\n",
    "    u'STICKCPIXSHLTRM158SFRBATL', u'W004RZ2Q224SBEA', u'W087RA3Q086SBEA',\n",
    "    u'W111RA3Q086SBEA', u'W117RL1Q225SBEA', u'W130RA3Q086SBEA',\n",
    "    u'W368RG3Q066SBEA', u'WAAA', u'WGS10YR', u'WTB3MS',\n",
    "    u'Y020RY2Q224SBEA', u'Y033RV1Q225SBEA', u'Y033RZ2Q224SBEA',\n",
    "    u'Y034RA3Q086SBEA', u'Y034RY2Q224SBEA', u'Y052RL1Q225SBEA',\n",
    "    u'Y054RG3Q086SBEA', u'Y060RZ2Q224SBEA', u'Y694RY2Q224SBEA']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the metadata\n",
    "We'll be needing to know the frequency of the observations in order\n",
    "to merge the data correctly. That information is available from the\n",
    "API. Each call to `get_series_info` involves an API call, so this may\n",
    "take some time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "metadata = {}\n",
    "for series_id in good_columns:\n",
    "    try:\n",
    "        metadata[series_id] = fred.get_series_info(series_id)\n",
    "    except ValueError:\n",
    "        # Series sometimes get retired from FRED\n",
    "        warnings.warn('Series {} not found on FRED API'.format(series_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the data\n",
    "This is where we actually acquire the data. This next step may take a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_series_data(series_id):\n",
    "    series_data = fred.get_series_first_release(series_id)\n",
    "\n",
    "    series_index = [ix.strftime('%Y-%m-%d') for ix in series_data.index]\n",
    "    series_data.index = series_index\n",
    "    return series_data\n",
    "\n",
    "obs = {}\n",
    "for series_id in metadata.keys():\n",
    "    series_data = get_series_data(series_id)\n",
    "    obs[series_id] = series_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organize by data frequency\n",
    "Here we make a few groups of the series we just acquired. The ones that\n",
    "have the same update frequency can be put into one dataframe very easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weekly = [series_id for series_id, meta\n",
    "          in metadata.iteritems()\n",
    "          if meta['frequency'] == 'Weekly, Ending Friday']\n",
    "quarterly = [series_id for series_id, meta\n",
    "             in metadata.iteritems()\n",
    "             if meta['frequency'] == 'Quarterly']\n",
    "monthly = [series_id for series_id, meta\n",
    "           in metadata.iteritems()\n",
    "           if meta['frequency'] == 'Monthly']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_weekly = pd.DataFrame({metadata[series_id]['title']: obs[series_id]\n",
    "                           for series_id in weekly})\n",
    "\n",
    "all_monthly = pd.DataFrame({metadata[series_id]['title']: obs[series_id]\n",
    "                            for series_id in monthly})\n",
    "\n",
    "all_quarterly = pd.DataFrame({metadata[series_id]['title']: obs[series_id]\n",
    "                              for series_id in quarterly})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine the data of different frequencies\n",
    "We wrote a little helper to take care of merging dataframes that have\n",
    "differing date indexes. It comes in handy right here.\n",
    "\n",
    "We also drop some rows that extend into the future - some of the series from\n",
    "FRED come back like that, and it's not good for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fin_data = timetools.expand_frame_merge(all_weekly, all_monthly)\n",
    "fin_data = timetools.expand_frame_merge(fin_data, all_quarterly)\n",
    "\n",
    "fin_data = fin_data[fin_data.index <\n",
    "                    datetime.datetime.today().strftime('%Y-%m-%d')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the target\n",
    "The whole point of all this is to see if we can predict if there will be a\n",
    "recession in the future, so we'll need to get historical data on the state\n",
    "of the US economy.  \n",
    "\n",
    "Of course, predicting if we are in a recession on any given day is kind of \n",
    "a no-brainer. So we'll slide the series in such a way that for any given\n",
    "date, we're looking at whether there is a recession 13 weeks from that day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "usrec = fred.get_series_first_release('USREC')\n",
    "usrec.index = [ix.isoformat().split('T')[0] for ix in usrec.index]\n",
    "bool_match = usrec.index > '1918-01-01'\n",
    "target_series = usrec[bool_match]\n",
    "\n",
    "\n",
    "target_name = 'US Recession in 13 Weeks'\n",
    "timetools.slide(target_series, 7 * 13)\n",
    "target_frame = pd.DataFrame({target_name: target_series})\n",
    "\n",
    "\n",
    "modeling_frame = timetools.expand_frame_merge(fin_data, target_frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trim some (mostly useless) data\n",
    "\n",
    "Some of these series only started gathering data in the late 1940's. So we'll\n",
    "just drop rows from before then, since there isn't much information in those\n",
    "weeks. While this step isn't necessary, it does mean we'll be modeling on \n",
    "some more informative data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "na_counts = modeling_frame.isnull().sum(axis=1)\n",
    "earliest_useful_day = na_counts[na_counts < 20].index[0]\n",
    "earliest_useful_day\n",
    "\n",
    "modeling_frame = modeling_frame[modeling_frame.index >= earliest_useful_day]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the partition column\n",
    "We'll be training on data before 1980, validating on data from 1980 to 1995, and withholding the data for 1995 onward. This is mostly arbitrary, but does ensure that each time interval has more than one recession. If we \n",
    "create a column with these labels, DataRobot will let us use that column to partition the data into \n",
    "training, validation, and holdout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_rows = len(modeling_frame)\n",
    "\n",
    "validation_first_day = modeling_frame[modeling_frame.index >=\n",
    "                                      '1980-01-01'].index[0]\n",
    "validation_point = modeling_frame.index.get_loc(validation_first_day)\n",
    "holdout_first_day = modeling_frame[modeling_frame.index >=\n",
    "                                   '1995-01-01'].index[0]\n",
    "holdout_point = modeling_frame.index.get_loc(holdout_first_day)\n",
    "\n",
    "tvh = pd.Series(['T'] * n_rows)\n",
    "tvh.loc[validation_point:holdout_point] = 'V'\n",
    "tvh.loc[holdout_point:] = 'H'\n",
    "tvh.index = modeling_frame.index\n",
    "\n",
    "modeling_frame['TVH'] = tvh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the dataset to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fname = 'financials-{}.csv'.format(datetime.datetime.today().\n",
    "                                   strftime('%Y-%m-%d'))\n",
    "modeling_frame.to_csv(fname, index=True, index_label='Date', encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
